{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de91130d-7c91-4e3f-989b-e88d7eac0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd41786-12e8-4879-8a79-e4c293c7cb4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and Save Statement and Statistics for Mt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a5767-ca33-4f03-b7ed-90e582196a8e",
   "metadata": {},
   "source": [
    "### Load Statement list ids from MQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930e5230-4317-41d6-ba87-e336aaf7bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605\n"
     ]
    }
   ],
   "source": [
    "total_pages = 35\n",
    "mt5idlist=[]\n",
    "for i in range(1, total_pages):\n",
    "    url = 'https://www.mql5.com/en/signals/mt5/list/page' + str(i)\n",
    "    r = requests.get(url)\n",
    "    htmlContent = r.content\n",
    "    soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "    ids = soup.find_all(\"div\", class_=\"button button_white-and-green\")\n",
    "    mt5idlist.extend( [p['data-id'] for p in ids])\n",
    "    time.sleep(random.randint(3, 5))\n",
    "\n",
    "print(len(mt5idlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d4c0da-9c3b-48d1-b63e-1bdc37b8cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of statistics Loaded:  1665\r"
     ]
    }
   ],
   "source": [
    "mypath = \"./Data/mt5/\"\n",
    "headers = {'cookie': 'lang=en; _fz_uniq=5046613820310397396; sid=CfDJ8O2AwCds3ABPuSmyNNtvSt59939oGNEye%2FAwZ1mc%2Bh8DRzt0jnReqBNR524tV5qZIsr8GVykBZl2Z4zVTBU6sxte3NKv46eSA7DQm92uYH2YWEHBdd76%2Fy7Y8k4Pzmrgkxcf9b8E0yZM3idvhMJ2yoVo9KVTdZUjCkCIMoTN6qkS; _fz_fvdt=1586144823; mt5_download_button=1613974670; _media_uuid=3691831371; auth=41yAG1RvddnKpurvZe6_JvusfPWFb0ci-HeJqQV2Rf8nOX0seYrMwizlRaa3j802MeX9_WxL6YM2NSh8YR3zTmgdMjyO23STt8e4rWIoRUxgiQs_nF_Hovy-tVjyGubYZKlNT9suLWjkUKfDSfppVQ; _fz_ssn=1658294788431610449'}\n",
    "\n",
    "\n",
    "\n",
    "# # create DataFrame for statement\n",
    "# if not os.path.isfile(mypath + \"statement.csv\"):    \n",
    "#     url = 'https://www.mql5.com/en/signals/'+ idlist[0] + '/export/positions'\n",
    "#     response = requests.get(url, headers=headers)\n",
    "\n",
    "#     state_df = pd.read_csv(io.BytesIO(response.content), delimiter=';')\n",
    "#     state_df.insert(loc=0, column='id', value=int(idlist[0]))\n",
    "\n",
    "#     state_df.to_csv(mypath + \"statement.csv\")\n",
    "#     time.sleep(random.randint(3, 10))\n",
    "\n",
    "# create DataFrame for statistics\n",
    "if not os.path.isfile(mypath + \"statistics.csv\"):    \n",
    "    url = 'https://www.mql5.com/en/signals/'+ mt5idlist[0] + '?source=Site+Signals+MT5+Tile'\n",
    "    r = requests.get(url)\n",
    "    htmlContent = r.content\n",
    "    soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "    labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "    values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "    cols = ['id']\n",
    "    for i in range(len(labels)):\n",
    "        cols.append( labels[i].strip().split(':')[0] )\n",
    "    statistics_df = pd.DataFrame(columns=list(dict.fromkeys(cols)))\n",
    "    statistics_df.to_csv(mypath + \"statistics.csv\")\n",
    "    time.sleep(random.randint(3, 10))\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "fileIds = [f.split('.')[0] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "statment_count = len(fileIds)\n",
    "# statistics_df = pd.read_csv(mypath + \"statistics.csv\", index_col=[0])\n",
    "# state_count = len(statistics_df)\n",
    "# statistics_df\n",
    "for id in mt5idlist:\n",
    "    # pass\n",
    "    # load mt5 statements\n",
    "    if id not in fileIds:\n",
    "        url = 'https://www.mql5.com/en/signals/' + id + '/export/positions'\n",
    "        response = requests.get(url, headers=headers)  \n",
    "        csv_file = open( mypath + id + '.csv', 'wb')\n",
    "        csv_file.write(response.content)\n",
    "        csv_file.close()  \n",
    "    \n",
    "        print ('Number of statement Loaded: ', len([f.split('.')[0] for f in listdir(mypath) if isfile(join(mypath, f))]), end=\"\\r\")\n",
    "        time.sleep(random.randint(3, 10))\n",
    "\n",
    "        \n",
    "# fileIds = [f.split('.')[0] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# statment_count = len(fileIds)\n",
    "\n",
    "# state_df = pd.read_csv(mypath + \"statement.csv\", index_col=[0])\n",
    "# for id in mt5idlist:\n",
    "#     # pass\n",
    "#     # load mt5 statements\n",
    "#     if int(id) not in  state_df.id.values:\n",
    "#         url = 'https://www.mql5.com/en/signals/' + id + '/export/positions'\n",
    "#         response = requests.get(url, headers=headers)  \n",
    "        \n",
    "#         temp = pd.read_csv(io.BytesIO(response.content), delimiter=';')\n",
    "#         temp.insert(loc=0, column='id', value=int(id))\n",
    "\n",
    "#         state_df = pd.concat([state_df, temp])\n",
    "        \n",
    "#         state_df.to_csv(mypath + \"statement.csv\")\n",
    "    \n",
    "#         print ('Loaded: ', len(np.unique(state_df.id.values)), end=\"\\r\")\n",
    "#         time.sleep(random.randint(3, 9))\n",
    "    \n",
    "    # load mt5 Statistics\n",
    "    statistics_df = pd.read_csv(mypath + \"statistics.csv\", index_col=[0])\n",
    "    if int(id) not in  statistics_df.id.values:\n",
    "        url = 'https://www.mql5.com/en/signals/' + id + '?source=Site+Signals+MT5+Tile'\n",
    "        response = requests.get(url, headers=headers)  \n",
    "        htmlContent = response.content\n",
    "        soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "        labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "        values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "        dic = {}\n",
    "        dic['id'] = int(id)\n",
    "        for i in range(len(labels)):\n",
    "            dic[labels[i].strip().split(':')[0]] = values[i].strip()\n",
    "        temp_df = pd.DataFrame(dic, index=[0])\n",
    "        statistics_df = pd.concat([statistics_df, temp_df])\n",
    "        \n",
    "        statistics_df.to_csv(mypath + \"statistics.csv\")\n",
    "        \n",
    "        print ('Number of statistics Loaded: ', len(statistics_df), end=\"\\r\")\n",
    "        time.sleep(random.randint(3, 10))    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b0a0d-5918-4c8b-be65-a96762e05c7e",
   "metadata": {},
   "source": [
    "# Load and Save Statement and Statistics fo Mt4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc912a-e1aa-4cc4-8757-43a3f5633fdf",
   "metadata": {},
   "source": [
    "## Load Statement list ids from MQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9343794-eb99-4da1-8405-603d298f78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n"
     ]
    }
   ],
   "source": [
    "total_pages = 91\n",
    "mt4idlist=[]\n",
    "for i in range(1, total_pages):\n",
    "    url = 'https://www.mql5.com/en/signals/mt4/list/page' + str(i)\n",
    "    r = requests.get(url)\n",
    "    htmlContent = r.content\n",
    "    soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "    ids = soup.find_all(\"div\", class_=\"button button_white-and-green\")\n",
    "    mt4idlist.extend( [p['data-id'] for p in ids])\n",
    "    time.sleep(random.randint(3, 5))\n",
    "    \n",
    "mt4idlist = list(dict.fromkeys(mt4idlist))\n",
    "print(len(mt4idlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1f0cc-64c5-4e5b-8c3c-0cde2611cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"./Data/mt4/\"\n",
    "headers = {'cookie': 'lang=en; _fz_uniq=5046613820310397396; sid=CfDJ8O2AwCds3ABPuSmyNNtvSt59939oGNEye%2FAwZ1mc%2Bh8DRzt0jnReqBNR524tV5qZIsr8GVykBZl2Z4zVTBU6sxte3NKv46eSA7DQm92uYH2YWEHBdd76%2Fy7Y8k4Pzmrgkxcf9b8E0yZM3idvhMJ2yoVo9KVTdZUjCkCIMoTN6qkS; _fz_fvdt=1586144823; mt5_download_button=1613974670; _media_uuid=3691831371; auth=41yAG1RvddnKpurvZe6_JvusfPWFb0ci-HeJqQV2Rf8nOX0seYrMwizlRaa3j802MeX9_WxL6YM2NSh8YR3zTmgdMjyO23STt8e4rWIoRUxgiQs_nF_Hovy-tVjyGubYZKlNT9suLWjkUKfDSfppVQ; _fz_ssn=1658294788431610449'}\n",
    "\n",
    "# create DataFrame for statistics\n",
    "if not os.path.isfile(mypath + \"statistics.csv\"):    \n",
    "    url = 'https://www.mql5.com/en/signals/'+ idlist[0] + '?source=Site+Signals+MT5+Tile'\n",
    "    r = requests.get(url)\n",
    "    htmlContent = r.content\n",
    "    soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "    labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "    values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "    cols = ['id']\n",
    "    for i in range(len(labels)):\n",
    "        cols.append( labels[i].strip().split(':')[0] )\n",
    "    statistics_df = pd.DataFrame(columns=list(dict.fromkeys(cols)))\n",
    "    statistics_df.to_csv(mypath + \"statistics.csv\")\n",
    "    time.sleep(random.randint(3, 10))\n",
    "\n",
    "\n",
    "\n",
    "fileIds = [f.split('.')[0] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "statment_count = len(fileIds)\n",
    "state_count = len(statistics_df)\n",
    "\n",
    "for id in mt4idlist:\n",
    "    # pass\n",
    "    # load mt5 statements\n",
    "    if id not in fileIds:\n",
    "        url = 'https://www.mql5.com/en/signals/' + id + '/export/history'\n",
    "        response = requests.get(url, headers=headers)  \n",
    "        csv_file = open( mypath + id + '.csv', 'wb')\n",
    "        csv_file.write(response.content)\n",
    "        csv_file.close()  \n",
    "    \n",
    "        print ('Loaded: ', statment_count, end=\"\\r\")\n",
    "        statment_count += 1    \n",
    "        time.sleep(random.randint(3, 10))\n",
    "    \n",
    "    # load mt5 Statistics\n",
    "    statistics_df = pd.read_csv(mypath + \"statistics.csv\", index_col=[0])\n",
    "    if int(id) not in  statistics_df.id.values:\n",
    "        url = 'https://www.mql5.com/en/signals/' + id + '?source=Site+Signals+MT5+Tile'\n",
    "        response = requests.get(url, headers=headers)  \n",
    "        htmlContent = response.content\n",
    "        soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "        labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "        values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "        dic = {}\n",
    "        dic['id'] = int(id)\n",
    "        for i in range(len(labels)):\n",
    "            dic[labels[i].strip().split(':')[0]] = values[i].strip()\n",
    "        temp_df = pd.DataFrame(dic, index=[0])\n",
    "        statistics_df = pd.concat([statistics_df, temp_df])\n",
    "        \n",
    "        statistics_df.to_csv(mypath + \"statistics.csv\")\n",
    "        \n",
    "        print ('Loaded: ', len(statistics_df), end=\"\\r\")\n",
    "        time.sleep(random.randint(3, 10))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182b5f3-3b9e-471f-856a-8f2e0a197a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2fd4d8f-0a40-417f-9efd-53bcf85966b6",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba4f89b-cc49-473f-ba4e-70d9f2676903",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e333a879-a00b-41a9-9c55-3d98c39280a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mql5.com/en/signals/1431540?source=Site+Signals+MT5+Tile'\n",
    "r = requests.get(url)\n",
    "htmlContent = r.content\n",
    "soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e4f621b-7ec7-4bcc-be7c-266807dde49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Trades</th>\n",
       "      <th>Profit Trades</th>\n",
       "      <th>Loss Trades</th>\n",
       "      <th>Best trade</th>\n",
       "      <th>Worst trade</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Gross Loss</th>\n",
       "      <th>Maximum consecutive wins</th>\n",
       "      <th>Maximal consecutive profit</th>\n",
       "      <th>...</th>\n",
       "      <th>Average Loss</th>\n",
       "      <th>Maximum consecutive losses</th>\n",
       "      <th>Maximal consecutive loss</th>\n",
       "      <th>Monthly growth</th>\n",
       "      <th>Annual Forecast</th>\n",
       "      <th>Algo trading</th>\n",
       "      <th>Absolute</th>\n",
       "      <th>Maximal</th>\n",
       "      <th>By Balance</th>\n",
       "      <th>By Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, Trades, Profit Trades, Loss Trades, Best trade, Worst trade, Gross Profit, Gross Loss, Maximum consecutive wins, Maximal consecutive profit, Sharpe Ratio, Trading activity, Max deposit load, Latest trade, Trades per week, Avg holding time, Recovery Factor, Long Trades, Short Trades, Profit Factor, Expected Payoff, Average Profit, Average Loss, Maximum consecutive losses, Maximal consecutive loss, Monthly growth, Annual Forecast, Algo trading, Absolute, Maximal, By Balance, By Equity]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create DataFrame\n",
    "url = 'https://www.mql5.com/en/signals/1431540?source=Site+Signals+MT5+Tile'\n",
    "r = requests.get(url)\n",
    "htmlContent = r.content\n",
    "soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "cols = ['id']\n",
    "for i in range(len(labels)):\n",
    "    cols.append( labels[i].strip().split(':')[0] )\n",
    "df = pd.DataFrame(columns=list(dict.fromkeys(cols)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26f41108-5a41-45ea-b9ff-62557f01092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  1\r"
     ]
    }
   ],
   "source": [
    "headers = {'cookie': '_fz_uniq=5044931279740993001; _fz_fvdt=1641843692; utm_source=web.installer; utm_campaign=mql5.welcome.open; auth=41yAG1RvddnKpurvZe6_JvusfPWFb0ci-HeJqQV2Rf_kFNKZ8py9uQsT22Xv9Xy5pc2Kbg0mXQN1rfpSYKfAFeynF_fvj3j6hOOQ-AV7KhBDDRD56SqEkbRLDIQb_GFxCBkr3Ho7C4dVHqFxKiUdqA; lang=en; sid=CfDJ8O2AwCds3ABPuSmyNNtvSt6WryiUlauSGF3Omd3riSC9WE%2FHe9%2FrciGEP8ZCl2K24QrTLCd8tkU%2BrywuW2AeMGKlzo4xxba4JgJy45%2FU1lx0515Y2zy6p3z38kMPTteePyO6iisFJMfkKXkyr5tw8vk5iMxd1FWn%2BWVbLwmD%2Bsr5'}  \n",
    "\n",
    "# count = len(df)\n",
    "# df2 = None\n",
    "for id in idlist[:1]:\n",
    "    if int(id) in  df.id.values:\n",
    "        continue\n",
    "    url = 'https://www.mql5.com/en/signals/' + '843451' + '?source=Site+Signals+MT5+Tile'\n",
    "    response = requests.get(url, headers=headers)  \n",
    "    htmlContent = response.content\n",
    "    soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "    labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "    values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "    dic = {}\n",
    "    dic['id'] = int(id)\n",
    "    for i in range(len(labels)):\n",
    "        dic[labels[i].strip().split(':')[0]] = values[i].strip()\n",
    "    df1 = pd.DataFrame(dic, index=[0])\n",
    "    df = pd.concat([df, df1])# , ignore_index=True)\n",
    "   \n",
    "    # count += 1    \n",
    "    print ('Loaded: ', len(df), end=\"\\r\")\n",
    "    time.sleep(random.randint(3, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cc85e4e8-909c-4f5d-9c67-12989d42b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Profit'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6e4198f-d521-4b29-a84e-248ebf0309f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  3\r"
     ]
    }
   ],
   "source": [
    "mypath = \"./Data/\"\n",
    "headers = {'cookie': 'lang=en; _fz_uniq=5046613820310397396; sid=CfDJ8O2AwCds3ABPuSmyNNtvSt59939oGNEye%2FAwZ1mc%2Bh8DRzt0jnReqBNR524tV5qZIsr8GVykBZl2Z4zVTBU6sxte3NKv46eSA7DQm92uYH2YWEHBdd76%2Fy7Y8k4Pzmrgkxcf9b8E0yZM3idvhMJ2yoVo9KVTdZUjCkCIMoTN6qkS; _fz_fvdt=1586144823; mt5_download_button=1613974670; _media_uuid=3691831371; auth=41yAG1RvddnKpurvZe6_JvusfPWFb0ci-HeJqQV2Rf8nOX0seYrMwizlRaa3j802MeX9_WxL6YM2NSh8YR3zTmgdMjyO23STt8e4rWIoRUxgiQs_nF_Hovy-tVjyGubYZKlNT9suLWjkUKfDSfppVQ; _fz_ssn=1658294788431610449'}\n",
    "\n",
    "# create DataFrame for statement\n",
    "if not os.path.isfile(mypath + \"statement.csv\"):    \n",
    "    url = 'https://www.mql5.com/en/signals/'+ idlist[0] + '/export/positions'\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    state_df = pd.read_csv(io.BytesIO(response.content), delimiter=';')\n",
    "    state_df.insert(loc=0, column='id', value=int(idlist[0]))\n",
    "\n",
    "    state_df.to_csv(mypath + \"statement.csv\")\n",
    "    time.sleep(random.randint(3, 10))\n",
    "\n",
    "\n",
    "\n",
    "fileIds = [f.split('.')[0] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "statment_count = len(fileIds)\n",
    "# state_count = len(statistics_df)\n",
    "\n",
    "for id in idlist[:5]:\n",
    "    # pass\n",
    "    # load mt5 statements\n",
    "    state_df = pd.read_csv(mypath + \"statement.csv\", index_col=[0])\n",
    "    if int(id) not in  state_df.id.values:\n",
    "        url = 'https://www.mql5.com/en/signals/' + id + '/export/positions'\n",
    "        response = requests.get(url, headers=headers)  \n",
    "        \n",
    "        temp = pd.read_csv(io.BytesIO(response.content), delimiter=';')\n",
    "        temp.insert(loc=0, column='id', value=int(id))\n",
    "\n",
    "        state_df = pd.concat([state_df, temp])\n",
    "        \n",
    "        state_df.to_csv(mypath + \"statement.csv\")\n",
    "    \n",
    "        print ('Loaded: ', statment_count, end=\"\\r\")\n",
    "        statment_count += 1    \n",
    "        time.sleep(random.randint(3, 10))\n",
    "        \n",
    "    \n",
    "    # load mt5 Statistics\n",
    "#     statistics_df = pd.read_csv(mypath + \"statistics.csv\", index_col=[0])\n",
    "#     if int(id) not in  statistics_df.id.values:\n",
    "#         url = 'https://www.mql5.com/en/signals/' + id + '?source=Site+Signals+MT5+Tile'\n",
    "#         response = requests.get(url, headers=headers)  \n",
    "#         htmlContent = response.content\n",
    "#         soup = bs.BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "#         labels = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__label\")]\n",
    "#         values = [x.get_text() for x in  soup.find_all(\"div\", class_=\"s-data-columns__value\")]\n",
    "\n",
    "#         dic = {}\n",
    "#         dic['id'] = int(id)\n",
    "#         for i in range(len(labels)):\n",
    "#             dic[labels[i].strip().split(':')[0]] = values[i].strip()\n",
    "#         temp_df = pd.DataFrame(dic, index=[0])\n",
    "#         statistics_df = pd.concat([statistics_df, temp_df])\n",
    "        \n",
    "#         statistics_df.to_csv(mypath + \"statistics.csv\")\n",
    "        \n",
    "#         print ('Loaded: ', len(statistics_df), end=\"\\r\")\n",
    "#         time.sleep(random.randint(3, 10))    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6cfa25e-991d-4a89-b06f-9e97fe9afeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Type</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Price</th>\n",
       "      <th>Time.1</th>\n",
       "      <th>Price.1</th>\n",
       "      <th>Commission</th>\n",
       "      <th>Swap</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1487129</td>\n",
       "      <td>2022.08.12 10:26:01</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.12</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.02988</td>\n",
       "      <td>2022.08.12 10:49:40</td>\n",
       "      <td>1.02922</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1487129</td>\n",
       "      <td>2022.08.11 10:21:05</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.12</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.03246</td>\n",
       "      <td>2022.08.11 11:58:19</td>\n",
       "      <td>1.03380</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1487129</td>\n",
       "      <td>2022.08.10 11:42:42</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.12</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.02237</td>\n",
       "      <td>2022.08.10 12:31:15</td>\n",
       "      <td>1.02302</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1487129</td>\n",
       "      <td>2022.08.09 11:00:52</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.12</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.02159</td>\n",
       "      <td>2022.08.09 11:06:29</td>\n",
       "      <td>1.02230</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1487129</td>\n",
       "      <td>2022.08.08 10:31:54</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.12</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.01973</td>\n",
       "      <td>2022.08.08 10:38:04</td>\n",
       "      <td>1.02021</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>798045</td>\n",
       "      <td>2020.01.07 08:00:05</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.03</td>\n",
       "      <td>EURUSD</td>\n",
       "      <td>1.11834</td>\n",
       "      <td>2020.01.07 08:45:02</td>\n",
       "      <td>1.11874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>798045</td>\n",
       "      <td>2019.12.31 10:48:32</td>\n",
       "      <td>Balance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>798045</td>\n",
       "      <td>2019.12.10 14:18:35</td>\n",
       "      <td>Balance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10073.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>798045</td>\n",
       "      <td>2019.12.10 08:46:45</td>\n",
       "      <td>Credit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>798045</td>\n",
       "      <td>2019.12.09 09:11:24</td>\n",
       "      <td>Balance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10073.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8543 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 Time     Type  Volume  Symbol    Price  \\\n",
       "0     1487129  2022.08.12 10:26:01     Sell    0.12  EURUSD  1.02988   \n",
       "1     1487129  2022.08.11 10:21:05      Buy    0.12  EURUSD  1.03246   \n",
       "2     1487129  2022.08.10 11:42:42      Buy    0.12  EURUSD  1.02237   \n",
       "3     1487129  2022.08.09 11:00:52      Buy    0.12  EURUSD  1.02159   \n",
       "4     1487129  2022.08.08 10:31:54      Buy    0.12  EURUSD  1.01973   \n",
       "...       ...                  ...      ...     ...     ...      ...   \n",
       "6152   798045  2020.01.07 08:00:05      Buy    0.03  EURUSD  1.11834   \n",
       "6153   798045  2019.12.31 10:48:32  Balance     NaN     NaN      NaN   \n",
       "6154   798045  2019.12.10 14:18:35  Balance     NaN     NaN      NaN   \n",
       "6155   798045  2019.12.10 08:46:45   Credit     NaN     NaN      NaN   \n",
       "6156   798045  2019.12.09 09:11:24  Balance     NaN     NaN      NaN   \n",
       "\n",
       "                   Time.1  Price.1  Commission  Swap    Profit  \n",
       "0     2022.08.12 10:49:40  1.02922       -0.84   NaN      7.92  \n",
       "1     2022.08.11 11:58:19  1.03380       -0.84   NaN     16.08  \n",
       "2     2022.08.10 12:31:15  1.02302       -0.84   NaN      7.80  \n",
       "3     2022.08.09 11:06:29  1.02230       -0.84   NaN      8.52  \n",
       "4     2022.08.08 10:38:04  1.02021       -0.84   NaN      5.76  \n",
       "...                   ...      ...         ...   ...       ...  \n",
       "6152  2020.01.07 08:45:02  1.11874         NaN   NaN      1.20  \n",
       "6153                  NaN      NaN         NaN   NaN  10000.00  \n",
       "6154                  NaN      NaN         NaN   NaN -10073.00  \n",
       "6155                  NaN      NaN         NaN   NaN   3000.00  \n",
       "6156                  NaN      NaN         NaN   NaN  10073.24  \n",
       "\n",
       "[8543 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Data/statement.csv', index_col=[0])#.id.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
